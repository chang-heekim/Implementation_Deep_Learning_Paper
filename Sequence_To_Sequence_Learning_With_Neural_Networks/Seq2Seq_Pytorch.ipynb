{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq-Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPnmxz5xHKyYm/G/8ScP2lX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chang-heekim/Implementation_Deep_Learning_Paper/blob/main/Sequence_To_Sequence_Learning_With_Neural_Networks/Seq2Seq_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Donwload Spacy Libaray"
      ],
      "metadata": {
        "id": "FbWswohgIChH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuOoirJc9BP9",
        "outputId": "9d4a91ae-84a4-46b5-96cb-795364ae658c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-py3-none-any.whl size=14907055 sha256=be2ce356fc5060877299ca39cf98b68aafb6a1a6f759cb9871935b0c6ea3f530\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lwp13i9m/wheels/00/66/69/cb6c921610087d2cab339062345098e30a5ceb665360e7b32a\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Necessary Library & Set up Device, Hyper parameters"
      ],
      "metadata": {
        "id": "KE_h91JqIHYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "import spacy\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "H-3U5g4r9hPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 128\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "t0Lmf8nNrejQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data"
      ],
      "metadata": {
        "id": "dj-1fO9EIPEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_en = spacy.load('en')\n",
        "spacy_de = spacy.load('de')"
      ],
      "metadata": {
        "id": "HXR8imoe9l63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = spacy_en.tokenizer('Good to see you.')\n",
        "for idx, token in enumerate(tokenized):\n",
        "    print(f'{idx}: {token}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGWBWOPj9sKk",
        "outputId": "c46fee16-951b-4e18-977b-a70b7f867313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Good\n",
            "1: to\n",
            "2: see\n",
            "3: you\n",
            "4: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_en(text):\n",
        "    return[token.text for token in spacy_en.tokenizer(text)][::-1]\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return[token.text for token in spacy_de.tokenizer(text)]"
      ],
      "metadata": {
        "id": "wGFb0kKs-EJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True)\n",
        "TRG = Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<eos>', lower=True)"
      ],
      "metadata": {
        "id": "2NOnMM4zAhVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.de'), fields=(SRC,TRG))"
      ],
      "metadata": {
        "id": "aBpJT6_loV0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data.examples)}')\n",
        "print(f'Number of validation examples: {len(valid_data.examples)}')\n",
        "print(f'Number of testing examples: {len(test_data.examples)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7EUs_w_ouHx",
        "outputId": "3691b004-ca9c-4011-afe4-46e042dfc067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)\n",
        "\n",
        "print(f'length SRC: {len(SRC.vocab)}')\n",
        "print(f'length TRG: {len(TRG.vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51pRR1gMp8CI",
        "outputId": "d73df1c5-71f5-4be9-b41b-13ed05a29332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length SRC: 5893\n",
            "length TRG: 7855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=batch_size,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "OLgTpxOwq2bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in train_iterator:\n",
        "    src = text.src\n",
        "    trg = text.trg\n",
        "    for i in range(src.shape[0]):\n",
        "        print(f'Index {i}: {src[i][0].item()}')\n",
        "    \n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPHszErpr9G1",
        "outputId": "3f9911bd-52ba-471f-b4a6-3a5f50393a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 0: 2\n",
            "Index 1: 5\n",
            "Index 2: 1324\n",
            "Index 3: 1385\n",
            "Index 4: 18\n",
            "Index 5: 853\n",
            "Index 6: 33\n",
            "Index 7: 24\n",
            "Index 8: 4\n",
            "Index 9: 489\n",
            "Index 10: 10\n",
            "Index 11: 1211\n",
            "Index 12: 1534\n",
            "Index 13: 4\n",
            "Index 14: 3\n",
            "Index 15: 1\n",
            "Index 16: 1\n",
            "Index 17: 1\n",
            "Index 18: 1\n",
            "Index 19: 1\n",
            "Index 20: 1\n",
            "Index 21: 1\n",
            "Index 22: 1\n",
            "Index 23: 1\n",
            "Index 24: 1\n",
            "Index 25: 1\n",
            "Index 26: 1\n",
            "Index 27: 1\n",
            "Index 28: 1\n",
            "Index 29: 1\n",
            "Index 30: 1\n",
            "Index 31: 1\n",
            "Index 32: 1\n",
            "Index 33: 1\n",
            "Index 34: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Encdoer, Decoder, Seq2Seq\n"
      ],
      "metadata": {
        "id": "e9Gh3WWzIVj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, hid_dim, n_layers, dropout_prob):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "        self.rnn = nn.LSTM(embed_dim, hid_dim, n_layers, dropout=dropout_prob)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src shape: [Vocab Size, Batch_size]\n",
        "        embedding_layer = self.dropout(self.embedding(src))\n",
        "        # embedding_layer shape: [Vocab Size, Batch_size, Embed_dim]\n",
        "        \n",
        "        outputs, (hidden, cell) = self.rnn(embedding_layer)\n",
        "        # outputs shape: [Vocab Size, Batch_size, hid_dim]\n",
        "        # hidden shape: [n_layers, Batch_size, hid_dim] \n",
        "        # cell shape: [n_layers, Batch_size, hid_dim]\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "eKTBtcsrse2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout_prob):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, input, hidden, cell): \n",
        "        input = input.unsqueeze(0)\n",
        "        # input shape: [1, Batch_size]\n",
        "\n",
        "        embedding_layer = self.dropout(self.embedding(input))\n",
        "        # embedding_layer shape: [Vocab Size, Batch_size, Embed_dim]\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding_layer, (hidden, cell))\n",
        "        # outputs shape: [1, Batch_size, hid_dim]\n",
        "        # hidden shape: [n_layers, Batch_size, hid_dim] \n",
        "        # cell shape: [n_layers, Batch_size, hid_dim] \n",
        "\n",
        "        pred = self.fc(outputs.squeeze(0))\n",
        "        # pred shape: [Batch_size, output_dim]\n",
        "        return pred, hidden, cell"
      ],
      "metadata": {
        "id": "am0LbHCXOVxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n",
        "\n",
        "        input = trg[0, :]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            outputs[t] = output\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "NoeOx34gczHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to initialize model parameters"
      ],
      "metadata": {
        "id": "7lJ7QZ17IaST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)"
      ],
      "metadata": {
        "id": "1vISu1PRrj7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Model, Optimizer, Loss"
      ],
      "metadata": {
        "id": "fRRyxsrqIrh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(len(SRC.vocab), 256, 512, 2, 0.5)\n",
        "decoder = Decoder(len(TRG.vocab), 256, 512, 2, 0.5)\n",
        "model = Seq2Seq(encoder,decoder).to(device)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG.vocab.stoi[TRG.pad_token])"
      ],
      "metadata": {
        "id": "7IjgvEkJfRhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    current_loss = 0.0\n",
        "    print(f'[Epoch {epoch} / {epochs}] [', end='')\n",
        "    for idx, batch in enumerate(train_iterator):\n",
        "        src, trg = batch.src, batch.trg\n",
        "        output = model(src, trg)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "\n",
        "        trg = trg[1:].view(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "        \n",
        "        current_loss += loss.item()\n",
        "        if idx % 10 == 0:\n",
        "            print('-', end='')\n",
        "\n",
        "    train_loss = current_loss / len(train_iterator)\n",
        "    print(f'->] Train Loss: {train_loss}, Train PPL: {math.exp(train_loss):7.3f} ', end='')\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        for idx, batch in enumerate(valid_iterator):\n",
        "            src, trg = batch.src, batch.trg\n",
        "\n",
        "            output = model(src, trg, 0)\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            preds = output.argmax(1)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        val_loss = val_loss / len(valid_iterator)\n",
        "    print(f' Validation Loss: {val_loss}, Validation PPL: {math.exp(val_loss):7.3f}')"
      ],
      "metadata": {
        "id": "MZYU5E5f0roz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc7e4f1-b5ce-4867-fc2d-59be9b3be4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1 / 20] [------------------------>] Train Loss: 5.181033023128426, Train PPL: 177.866  Validation Loss: 5.0119956731796265, Validation PPL: 150.204\n",
            "[Epoch 2 / 20] [------------------------>] Train Loss: 4.585800250721398, Train PPL:  98.082  Validation Loss: 4.906110525131226, Validation PPL: 135.113\n",
            "[Epoch 3 / 20] [------------------------>] Train Loss: 4.291385308236277, Train PPL:  73.068  Validation Loss: 4.78971654176712, Validation PPL: 120.267\n",
            "[Epoch 4 / 20] [------------------------>] Train Loss: 4.083556217244018, Train PPL:  59.356  Validation Loss: 4.633901119232178, Validation PPL: 102.915\n",
            "[Epoch 5 / 20] [------------------------>] Train Loss: 3.928897341967679, Train PPL:  50.851  Validation Loss: 4.523829877376556, Validation PPL:  92.188\n",
            "[Epoch 6 / 20] [------------------------>] Train Loss: 3.8191933012218726, Train PPL:  45.567  Validation Loss: 4.488210707902908, Validation PPL:  88.962\n",
            "[Epoch 7 / 20] [------------------------>] Train Loss: 3.7105394344497884, Train PPL:  40.876  Validation Loss: 4.3788756132125854, Validation PPL:  79.748\n",
            "[Epoch 8 / 20] [------------------------>] Train Loss: 3.6027201986522925, Train PPL:  36.698  Validation Loss: 4.308506458997726, Validation PPL:  74.329\n",
            "[Epoch 9 / 20] [------------------------>] Train Loss: 3.512761419565142, Train PPL:  33.541  Validation Loss: 4.2807014882564545, Validation PPL:  72.291\n",
            "[Epoch 10 / 20] [------------------------>] Train Loss: 3.4013924367627384, Train PPL:  30.006  Validation Loss: 4.189609527587891, Validation PPL:  65.997\n",
            "[Epoch 11 / 20] [------------------------>] Train Loss: 3.3052858277039383, Train PPL:  27.256  Validation Loss: 4.124160677194595, Validation PPL:  61.816\n",
            "[Epoch 12 / 20] [------------------------>] Train Loss: 3.19024793061916, Train PPL:  24.294  Validation Loss: 4.056555777788162, Validation PPL:  57.775\n",
            "[Epoch 13 / 20] [------------------------>] Train Loss: 3.0857802645225356, Train PPL:  21.885  Validation Loss: 3.976655751466751, Validation PPL:  53.338\n",
            "[Epoch 14 / 20] [------------------------>] Train Loss: 3.0033025321456304, Train PPL:  20.152  Validation Loss: 3.933716058731079, Validation PPL:  51.097\n",
            "[Epoch 15 / 20] [------------------------>] Train Loss: 2.9203716563758344, Train PPL:  18.548  Validation Loss: 3.860466182231903, Validation PPL:  47.487\n",
            "[Epoch 16 / 20] [------------------------>] Train Loss: 2.814174325455653, Train PPL:  16.679  Validation Loss: 3.8384984731674194, Validation PPL:  46.456\n",
            "[Epoch 17 / 20] [------------------------>] Train Loss: 2.7162303714500124, Train PPL:  15.123  Validation Loss: 3.772131711244583, Validation PPL:  43.473\n",
            "[Epoch 18 / 20] [------------------------>] Train Loss: 2.6451218401282897, Train PPL:  14.085  Validation Loss: 3.7338958084583282, Validation PPL:  41.842\n",
            "[Epoch 19 / 20] [------------------------>] Train Loss: 2.5722309314206835, Train PPL:  13.095  Validation Loss: 3.750314235687256, Validation PPL:  42.534\n",
            "[Epoch 20 / 20] [------------------------>] Train Loss: 2.5059016832696184, Train PPL:  12.255  Validation Loss: 3.732545346021652, Validation PPL:  41.785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Test Dataset"
      ],
      "metadata": {
        "id": "ku59wocPIyHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0.0\n",
        "    for idx, batch in enumerate(test_iterator):\n",
        "        src, trg = batch.src, batch.trg\n",
        "\n",
        "        output = model(src, trg, 0)\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        preds = output.argmax(1)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    test_loss = test_loss / len(valid_iterator)\n",
        "print(f' Test Loss: {test_loss}, Test PPL: {math.exp(test_loss):7.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbei2k0H9gxY",
        "outputId": "5766e132-260f-4134-8d0d-6847550f8fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test Loss: 8.87286627292633, Test PPL: 7135.705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function that translates a single sentence"
      ],
      "metadata": {
        "id": "14-mc0tUI6rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
        "    model.eval() \n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token) \n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1]"
      ],
      "metadata": {
        "id": "LeamZ7yE_shV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translate Sentence"
      ],
      "metadata": {
        "id": "yx3fwBIIJOiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 1\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['src'][::-1]\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "\n",
        "print(f'Source Sequence: {\" \".join(src)}')\n",
        "print(f'Target Sequence: {\" \".join(trg)}')\n",
        "print(\"Pred Sequence:\", \" \".join(translate_sentence(src, SRC, TRG, model, device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7rYkc8Ik5l1",
        "outputId": "3f3c949b-10bc-4bf3-8ee7-11a34146a2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Sequence: man sitting using tool at a table in his home .\n",
            "Target Sequence: ein sitzender mann , der an einem tisch in seinem haus mit einem werkzeug arbeitet .\n",
            "Pred Sequence: ein mann singt in einem restaurant , während ein anderer mann auf dem . .\n"
          ]
        }
      ]
    }
  ]
}